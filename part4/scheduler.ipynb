{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6904c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "from time import sleep\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "from os import getpid\n",
    "\n",
    "import psutil\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38eeea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11T20:40:02.025217 start scheduler\n",
      "2025-05-11T20:40:02.025438 start memcached [0, 1] 2\n"
     ]
    }
   ],
   "source": [
    "# Start scheduler on CPU 0\n",
    "p = psutil.Process(getpid())\n",
    "p.cpu_affinity([0])\n",
    "print(f\"{datetime.now().isoformat()} start scheduler\")\n",
    "\n",
    "# Start memcached on CPU 0 and 1\n",
    "memcache_cores = [0, 1]\n",
    "#memcached_id = [p.pid for p in psutil.process_iter(['name']) if p.info['name'] == 'memcached'][0]\n",
    "#memcached = psutil.Process(memcached_id)\n",
    "#memcached.cpu_affinity([0, 1])\n",
    "print(f\"{datetime.now().isoformat()} start memcached {memcache_cores} {len(memcache_cores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a034e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_client = docker.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48af272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {\n",
    "    \"blackscholes\": \"anakli/cca:parsec_blackscholes\",\n",
    "    \"canneal\": \"anakli/cca:parsec_canneal\",\n",
    "    \"dedup\": \"anakli/cca:parsec_dedup\",\n",
    "    \"ferret\": \"anakli/cca:parsec_ferret\",\n",
    "    \"freqmine\": \"anakli/cca:parsec_freqmine\",\n",
    "    \"radix\": \"anakli/cca:splash2x_radix\",\n",
    "    \"vips\": \"anakli/cca:parsec_vips\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b454c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1361407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "poll_interval = 0.1  # seconds\n",
    "change_interval = 8 # seconds\n",
    "\n",
    "class DummyMemcachedStats:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.measurement = 0\n",
    "        self.measurement_time = time.time()\n",
    "\n",
    "    def read(self):\n",
    "        if time.time() - self.measurement_time > change_interval:\n",
    "            self.measurement = np.random.randint(0, 180000)\n",
    "            self.measurement_time = time.time()\n",
    "    \n",
    "    # queries received in the last count*10ms\n",
    "    def last_measurements(self, count=10):\n",
    "        self.read()\n",
    "        return self.measurement\n",
    "\n",
    "    def qps(self):\n",
    "        return self.last_measurements(int(1/poll_interval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d68506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = DummyMemcachedStats()\n",
    "# for i in range(20):\n",
    "#    print(tmp.last_measurements())\n",
    "#    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64942d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a67c9b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting queue:\n",
      "  radix: 1.95, 43 8\n",
      "  canneal: 1.7, 220 9\n",
      "  blackscholes: 1.7, 100 9\n",
      "  dedup: 1.7, 16 10\n",
      "  freqmine: 1.95, 394 11\n",
      "  ferret: 1.95, 288 11\n",
      "  vips: 1.95, 82 11\n"
     ]
    }
   ],
   "source": [
    "scaling = [1.70, 1.70, 1.70, 1.95, 1.95, 1.95, 1.95]\n",
    "duration = [100, 220, 16, 288, 394, 43, 82]\n",
    "interference = [9, 9, 10, 11, 11, 8, 11]\n",
    "\n",
    "jobs = list(zip(image_dict.keys(), scaling, duration, interference))\n",
    "\n",
    "start_queue = sorted(jobs, key=lambda x: (x[3], -x[2], x[1]), reverse=False)\n",
    "print(\"Starting queue:\")\n",
    "for job in start_queue:\n",
    "    print(f\"  {job[0]}: {job[1]}, {job[2]} {job[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5df035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97a4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    def __init__(self, name, scaling, duration, inteference):\n",
    "        self.name = name\n",
    "        self.scaling = scaling\n",
    "        self.duration = duration\n",
    "        self.interference = inteference\n",
    "        self.image_name = image_dict[name]\n",
    "        self.container = None\n",
    "        self.cpuset_cpus = \"\"\n",
    "        self.start_time = None  # Initialize start_time to None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Job({self.name}, {self.scaling}, {self.duration}, {self.interference})\"\n",
    "    \n",
    "    def is_scaling_job(self):\n",
    "        return self.scaling > 1.9 and self.interference > 10\n",
    "    \n",
    "    def set_container(self, container):\n",
    "        self.container = container\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def update_cpusets_cpu(self, additional_cpus):\n",
    "        self.cpuset_cpus += f\",{additional_cpus}\" if self.cpuset_cpus else additional_cpus\n",
    "\n",
    "        self.container.reload()\n",
    "        if self.container.status == 'running':\n",
    "            self.container.update(cpuset_cpus=self.cpuset_cpus)\n",
    "\n",
    "    def remove_cpu(self, cpu):\n",
    "        # Fix the remove_cpu method\n",
    "        cpu_list = self.cpuset_cpus.split(\",\")\n",
    "        if cpu in cpu_list:\n",
    "            cpu_list.remove(cpu)\n",
    "            self.cpuset_cpus = \",\".join(cpu_list)\n",
    "            self.container.update(cpuset_cpus=self.cpuset_cpus)\n",
    "\n",
    "    def runtime(self):\n",
    "        if self.start_time:\n",
    "            return time.time() - self.start_time\n",
    "        return 0\n",
    "    \n",
    "    def is_finished(self):\n",
    "        if not self.container:\n",
    "            return False        \n",
    "        try:\n",
    "            self.container.reload()\n",
    "            return self.container.status == 'exited'\n",
    "        except:\n",
    "            # Container might be removed already\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c01d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11T20:40:02.317675 updated_cores memcached [0]\n",
      "2025-05-11T20:40:02.961200 start radix [1] 1\n",
      "2025-05-11T20:40:03.351299 start canneal [2] 1\n",
      "2025-05-11T20:40:03.696843 start blackscholes [3] 1\n",
      "2025-05-11T20:40:10.368973 custom memcached new QPS: 37978\n",
      "2025-05-11T20:40:26.484214 custom memcached new QPS: 109278\n",
      "2025-05-11T20:40:26.504164 pause radix\n",
      "2025-05-11T20:40:26.504210 updated_cores memcached [0, 1]\n",
      "2025-05-11T20:40:34.549922 custom memcached new QPS: 166178\n",
      "2025-05-11T20:40:42.563708 custom memcached new QPS: 99792\n",
      "2025-05-11T20:40:42.563776 updated_cores memcached [0]\n",
      "2025-05-11T20:40:42.607835 unpause radix\n",
      "2025-05-11T20:40:50.595210 custom memcached new QPS: 159977\n",
      "2025-05-11T20:40:50.618371 pause radix\n",
      "2025-05-11T20:40:50.618435 updated_cores memcached [0, 1]\n",
      "2025-05-11T20:40:58.655024 custom memcached new QPS: 109413\n",
      "2025-05-11T20:41:06.697962 custom memcached new QPS: 96970\n",
      "2025-05-11T20:41:06.698031 updated_cores memcached [0]\n",
      "2025-05-11T20:41:06.737249 unpause radix\n",
      "2025-05-11T20:41:10.608662 end radix\n",
      "2025-05-11T20:41:10.608745 custom radix released [1]\n",
      "2025-05-11T20:41:10.948642 start dedup [1] 1\n",
      "2025-05-11T20:41:14.801326 pause dedup\n",
      "2025-05-11T20:41:14.801421 updated_cores memcached [0, 1]\n",
      "2025-05-11T20:41:22.828128 custom memcached new QPS: 26446\n",
      "2025-05-11T20:41:22.828226 updated_cores memcached [0]\n",
      "2025-05-11T20:41:22.889546 unpause dedup\n",
      "2025-05-11T20:41:30.897399 custom memcached new QPS: 38501\n",
      "2025-05-11T20:41:38.934928 custom memcached new QPS: 71002\n",
      "2025-05-11T20:41:45.550385 end dedup\n",
      "2025-05-11T20:41:45.550449 custom dedup released [1]\n",
      "2025-05-11T20:41:45.892227 start freqmine [1] 3\n",
      "2025-05-11T20:41:46.950978 custom memcached new QPS: 23929\n",
      "2025-05-11T20:41:54.209446 end blackscholes\n",
      "2025-05-11T20:41:54.209522 custom blackscholes released [3]\n",
      "Added CPU 3 to freqmine\n",
      "2025-05-11T20:41:54.232881 updated_cores freqmine [1, 3]\n",
      "2025-05-11T20:41:54.962019 custom memcached new QPS: 12469\n",
      "2025-05-11T20:42:03.010919 custom memcached new QPS: 132961\n",
      "2025-05-11T20:42:03.030532 updated_cores freqmine [0]\n",
      "2025-05-11T20:42:03.030577 custom freqmine released CPU 1\n",
      "2025-05-11T20:42:03.030590 updated_cores memcached [0, 1]\n",
      "2025-05-11T20:42:11.055974 custom memcached new QPS: 843\n",
      "2025-05-11T20:42:11.056044 updated_cores memcached [0]\n",
      "Added CPU 1 to freqmine\n",
      "2025-05-11T20:42:11.084046 updated_cores freqmine [3, 1]\n",
      "2025-05-11T20:42:19.105371 custom memcached new QPS: 62452\n",
      "2025-05-11T20:42:27.121348 custom memcached new QPS: 79077\n",
      "2025-05-11T20:42:35.140702 custom memcached new QPS: 8517\n",
      "2025-05-11T20:42:43.152487 custom memcached new QPS: 96881\n",
      "2025-05-11T20:42:51.220585 custom memcached new QPS: 47803\n",
      "2025-05-11T20:42:58.199748 end canneal\n",
      "2025-05-11T20:42:58.199816 custom canneal released [2]\n",
      "Added CPU 2 to freqmine\n",
      "2025-05-11T20:42:58.220105 updated_cores freqmine [3, 1, 2]\n",
      "2025-05-11T20:42:59.244165 custom memcached new QPS: 30964\n",
      "2025-05-11T20:43:07.314830 custom memcached new QPS: 149013\n",
      "2025-05-11T20:43:07.346039 updated_cores freqmine [0]\n",
      "2025-05-11T20:43:07.346109 custom freqmine released CPU 1\n",
      "2025-05-11T20:43:07.346132 updated_cores memcached [0, 1]\n",
      "2025-05-11T20:43:15.315784 custom memcached new QPS: 166454\n",
      "2025-05-11T20:43:23.363510 custom memcached new QPS: 47087\n",
      "2025-05-11T20:43:23.363589 updated_cores memcached [0]\n",
      "Added CPU 1 to freqmine\n",
      "2025-05-11T20:43:23.392274 updated_cores freqmine [3, 2, 1]\n",
      "2025-05-11T20:43:31.427798 custom memcached new QPS: 126013\n",
      "2025-05-11T20:43:31.456734 updated_cores freqmine [0]\n",
      "2025-05-11T20:43:31.456793 custom freqmine released CPU 1\n",
      "2025-05-11T20:43:31.456819 updated_cores memcached [0, 1]\n",
      "2025-05-11T20:43:39.488203 custom memcached new QPS: 88370\n",
      "2025-05-11T20:43:39.488272 updated_cores memcached [0]\n",
      "Added CPU 1 to freqmine\n",
      "2025-05-11T20:43:39.511079 updated_cores freqmine [3, 2, 1]\n",
      "2025-05-11T20:43:55.584889 custom memcached new QPS: 100510\n",
      "2025-05-11T20:43:55.604905 updated_cores freqmine [0]\n",
      "2025-05-11T20:43:55.604949 custom freqmine released CPU 1\n",
      "2025-05-11T20:43:55.604961 updated_cores memcached [0, 1]\n",
      "2025-05-11T20:44:03.650889 custom memcached new QPS: 144793\n",
      "2025-05-11T20:44:19.701158 custom memcached new QPS: 16812\n",
      "2025-05-11T20:44:19.701232 updated_cores memcached [0]\n",
      "Added CPU 1 to freqmine\n",
      "2025-05-11T20:44:19.739365 updated_cores freqmine [3, 2, 1]\n",
      "2025-05-11T20:44:27.777435 custom memcached new QPS: 151218\n",
      "2025-05-11T20:44:27.798785 updated_cores freqmine [0]\n",
      "2025-05-11T20:44:27.798831 custom freqmine released CPU 1\n",
      "2025-05-11T20:44:27.798844 updated_cores memcached [0, 1]\n",
      "2025-05-11T20:44:43.852299 custom memcached new QPS: 103090\n",
      "2025-05-11T20:44:46.890688 end freqmine\n",
      "2025-05-11T20:44:46.890752 custom freqmine released [3, 2]\n",
      "2025-05-11T20:44:47.259762 start ferret [3] 3\n",
      "Added CPU 2 to ferret\n",
      "2025-05-11T20:44:47.294000 updated_cores ferret [3, 2]\n",
      "2025-05-11T20:44:51.871838 custom memcached new QPS: 159974\n",
      "2025-05-11T20:44:59.896384 custom memcached new QPS: 26273\n",
      "2025-05-11T20:44:59.896463 updated_cores memcached [0]\n",
      "Added CPU 1 to ferret\n",
      "2025-05-11T20:44:59.931187 updated_cores ferret [3, 2, 1]\n",
      "2025-05-11T20:45:07.968178 custom memcached new QPS: 48975\n",
      "2025-05-11T20:45:16.000842 custom memcached new QPS: 72778\n",
      "2025-05-11T20:45:24.030603 custom memcached new QPS: 153088\n",
      "2025-05-11T20:45:32.077166 custom memcached new QPS: 112152\n",
      "2025-05-11T20:45:40.153802 custom memcached new QPS: 176750\n",
      "2025-05-11T20:45:48.181184 custom memcached new QPS: 132635\n",
      "2025-05-11T20:45:56.221399 custom memcached new QPS: 121445\n",
      "2025-05-11T20:46:04.272257 custom memcached new QPS: 169669\n",
      "2025-05-11T20:46:12.321043 custom memcached new QPS: 70952\n",
      "2025-05-11T20:46:12.321118 updated_cores memcached [0]\n",
      "Added CPU 1 to ferret\n",
      "2025-05-11T20:46:12.344976 updated_cores ferret [3, 2, 1, 1]\n",
      "2025-05-11T20:46:20.377222 custom memcached new QPS: 166966\n",
      "2025-05-11T20:46:42.802345 end ferret\n",
      "2025-05-11T20:46:42.802409 custom ferret released [3, 2, 1, 1]\n",
      "2025-05-11T20:46:43.238861 start vips [3] 3\n",
      "Added CPU 2 to vips\n",
      "2025-05-11T20:46:43.261332 updated_cores vips [3, 2]\n",
      "2025-05-11T20:46:44.481752 custom memcached new QPS: 74133\n",
      "2025-05-11T20:46:44.481822 updated_cores memcached [0]\n",
      "Added CPU 1 to vips\n",
      "2025-05-11T20:46:44.553249 updated_cores vips [3, 2, 1]\n",
      "2025-05-11T20:46:52.521714 custom memcached new QPS: 176562\n",
      "2025-05-11T20:47:00.574912 custom memcached new QPS: 86397\n",
      "2025-05-11T20:47:00.575010 updated_cores memcached [0]\n",
      "Added CPU 1 to vips\n",
      "2025-05-11T20:47:00.610065 updated_cores vips [3, 2, 1, 1]\n",
      "2025-05-11T20:47:08.652139 custom memcached new QPS: 125272\n",
      "2025-05-11T20:47:15.388947 end vips\n",
      "2025-05-11T20:47:15.389010 custom vips released [3, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "start_queue = [Job(*job) for job in start_queue]\n",
    "curr_jobs: List[Job] = []\n",
    "\n",
    "avail_cpus = [\"2\", \"3\"]\n",
    "\n",
    "\n",
    "cpu_1_used = False\n",
    "cpu_1_job = None\n",
    "\n",
    "mem_cached_measurments = DummyMemcachedStats()\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "polling_interval = 0.1\n",
    "prev_qps = 0\n",
    "\n",
    "while len(start_queue) > 0 or len(curr_jobs) > 0:\n",
    "\n",
    "    # Check if any job has finished\n",
    "    for job in curr_jobs:\n",
    "        if job.is_finished():\n",
    "            \n",
    "            #print(f\"Job {job.name} completed after {job.runtime():.2f} seconds\")\n",
    "\n",
    "            # Free up the CPUs that were allocated to this job\n",
    "            job_cpus = [int(a) for a in job.cpuset_cpus.split(\",\")]\n",
    "            for cpu in job_cpus:\n",
    "                if cpu and cpu not in avail_cpus:\n",
    "                    avail_cpus.append(str(cpu))\n",
    "            \n",
    "            curr_jobs.remove(job)\n",
    "            if job == cpu_1_job:\n",
    "                cpu_1_job = None\n",
    "\n",
    "            print(f\"{datetime.now().isoformat()} end {job.name}\")\n",
    "            print(f\"{datetime.now().isoformat()} custom {job.name} released {job_cpus}\")\n",
    "\n",
    "    # Get the current CPU and QPS\n",
    "    cpu_cores_usage = psutil.cpu_percent(interval=None, percpu=True)\n",
    "    qps = mem_cached_measurments.last_measurements()\n",
    "\n",
    "    if abs(prev_qps - qps) > 10000:\n",
    "        print(f\"{datetime.now().isoformat()} custom memcached new QPS: {qps}\")\n",
    "        prev_qps = qps\n",
    "\n",
    "    if qps < 100000 and not cpu_1_used and not (\"1\" in avail_cpus):\n",
    "        # print(\"Low QPS, assigning more CPUS...\")\n",
    "        cpu_1_used = True\n",
    "        \n",
    "        avail_cpus.insert(0, \"1\")\n",
    "        \n",
    "        # TODO memcached.cpu_affinity([0])\n",
    "        print(f\"{datetime.now().isoformat()} updated_cores memcached [0]\")\n",
    "\n",
    "    elif (\"1\" in avail_cpus or cpu_1_used) and not (qps < 100000):\n",
    "        # print(\"High QPS, releasing CPU 1...\")\n",
    "        \n",
    "        cpu_1_used = False\n",
    "\n",
    "        if \"1\" in avail_cpus:\n",
    "            avail_cpus.remove(\"1\")\n",
    "\n",
    "        if cpu_1_job is None:\n",
    "            continue\n",
    "    \n",
    "        if len(cpu_1_job.cpuset_cpus.split(\",\")) == 1:\n",
    "            cpu_1_job.container.pause()\n",
    "            curr_jobs.remove(cpu_1_job)\n",
    "            start_queue.insert(0, cpu_1_job)\n",
    "            cpu_1_job.cpuset_cpus = \"\"\n",
    "            print(f\"{datetime.now().isoformat()} pause {cpu_1_job.name}\")\n",
    "            cpu_1_job = None\n",
    "        else:\n",
    "            cpu_1_job.remove_cpu(\"1\")\n",
    "            print(f\"{datetime.now().isoformat()} updated_cores {cpu_1_job.name} [0]\")\n",
    "            print(f\"{datetime.now().isoformat()} custom {cpu_1_job.name} released CPU 1\")\n",
    "\n",
    "        # TODO memcached.cpu_affinity([0, 1])\n",
    "        print(f\"{datetime.now().isoformat()} updated_cores memcached [0, 1]\")\n",
    "\n",
    "    if len(avail_cpus) == 0:\n",
    "        # print(\"No available CPUs, waiting...\")\n",
    "        sleep(polling_interval)\n",
    "        continue\n",
    "            \n",
    "    avail_cpu = avail_cpus.pop(0)\n",
    "\n",
    "    # If we have a scaling job, we do not need to pop\n",
    "    if len(start_queue) == 0:\n",
    "        scaling_jobs = [job for job in curr_jobs if job.is_scaling_job()] or curr_jobs\n",
    "    else:\n",
    "        scaling_jobs = [job for job in curr_jobs if job.is_scaling_job()]\n",
    "\n",
    "    if len(scaling_jobs) > 0:\n",
    "        scaling_job = scaling_jobs[0]\n",
    "\n",
    "        scaling_job.update_cpusets_cpu(avail_cpu)\n",
    "\n",
    "        cpuset_cpus = [int(a) for a in scaling_job.cpuset_cpus.split(\",\")]\n",
    "\n",
    "        print(f\"Added CPU {avail_cpu} to {scaling_job.name}\")\n",
    "        print(f\"{datetime.now().isoformat()} updated_cores {scaling_job.name} {cpuset_cpus}\")\n",
    "        continue\n",
    "    \n",
    "    if len(start_queue) == 0:\n",
    "        # No more jobs to start\n",
    "        sleep(polling_interval)\n",
    "        continue\n",
    "\n",
    "    #\n",
    "    job = start_queue.pop(0)\n",
    "\n",
    "    # Job already started but was paused\n",
    "    if job.container is not None:\n",
    "        \n",
    "        curr_jobs.append(job)\n",
    "        job.container.update(cpuset_cpus=avail_cpu)\n",
    "        job.cpuset_cpus = avail_cpu\n",
    "        job.container.unpause()\n",
    "        \n",
    "        if avail_cpu == \"1\":\n",
    "            cpu_1_job = job\n",
    "        else:\n",
    "            print(f\"{datetime.now().isoformat()} updated_cores {job.name} [{avail_cpu}]\")\n",
    "\n",
    "        print(f\"{datetime.now().isoformat()} unpause {job.name}\")\n",
    "        continue\n",
    "\n",
    "    run_command = (\n",
    "        \"./run -a run -S splash2x -p radix -i native -n 1\"\n",
    "        if job.name == \"radix\"\n",
    "        else f\"./run -a run -S parsec -p {job.name} -i native -n {3 if job.is_scaling_job() else 1}\"\n",
    "    )\n",
    "    \n",
    "    container = client.containers.run(\n",
    "        image=job.image_name,\n",
    "        command=run_command,\n",
    "        detach=True,\n",
    "        remove=True,\n",
    "        name=\"parsec-\" + job.name,\n",
    "        cpuset_cpus=avail_cpu,\n",
    "    )\n",
    "\n",
    "    \n",
    "    job.set_container(container)\n",
    "    job.cpuset_cpus = avail_cpu\n",
    "    curr_jobs.append(job)\n",
    "\n",
    "    if avail_cpu == \"1\":\n",
    "        cpu_1_job = job\n",
    "\n",
    "    print(f\"{datetime.now().isoformat()} start {job.name} {[int(a) for a in avail_cpu]} {3 if job.is_scaling_job() else 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d380b098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11T20:47:15.397568 end scheduler\n"
     ]
    }
   ],
   "source": [
    "print(f\"{datetime.now().isoformat()} end scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399aeef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c3125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136b72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
