{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6904c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "from time import sleep\n",
    "from typing import List, Dict, Any\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a034e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_client = docker.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48af272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {\n",
    "    \"blackscholes\": \"anakli/cca:parsec_blackscholes\",\n",
    "    \"canneal\": \"anakli/cca:parsec_canneal\",\n",
    "    \"dedup\": \"anakli/cca:parsec_dedup\",\n",
    "    \"ferret\": \"anakli/cca:parsec_ferret\",\n",
    "    \"freqmine\": \"anakli/cca:parsec_freqmine\",\n",
    "    \"radix\": \"anakli/cca:splash2x_radix\",\n",
    "    \"vips\": \"anakli/cca:parsec_vips\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67c9b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting queue:\n",
      "  radix: 1.95, 43 8\n",
      "  canneal: 1.7, 220 9\n",
      "  blackscholes: 1.7, 100 9\n",
      "  dedup: 1.7, 16 10\n",
      "  freqmine: 1.95, 394 11\n",
      "  ferret: 1.95, 288 11\n",
      "  vips: 1.95, 82 11\n"
     ]
    }
   ],
   "source": [
    "scaling = [1.70, 1.70, 1.70, 1.95, 1.95, 1.95, 1.95]\n",
    "duration = [100, 220, 16, 288, 394, 43, 82]\n",
    "inteference = [9, 9, 10, 11, 11, 8, 11]\n",
    "\n",
    "jobs = list(zip(image_dict.keys(), scaling, duration, inteference))\n",
    "\n",
    "start_queue = sorted(jobs, key=lambda x: (x[3], -x[2], x[1]), reverse=False)\n",
    "print(\"Starting queue:\")\n",
    "for job in start_queue:\n",
    "    print(f\"  {job[0]}: {job[1]}, {job[2]} {job[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d97a4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    def __init__(self, name, scaling, duration, inteference):\n",
    "        self.name = name\n",
    "        self.scaling = scaling\n",
    "        self.duration = duration\n",
    "        self.inteference = inteference\n",
    "        self.image_name = image_dict[name]\n",
    "        self.container = None\n",
    "        self.cpu_set = \"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Job({self.name}, {self.scaling}, {self.duration}, {self.inteference})\"\n",
    "    \n",
    "    def is_scaling_job(self):\n",
    "        return self.duration > 100 and self.scaling > 1.9\n",
    "    \n",
    "    def set_container(self, container):\n",
    "        self.container = container\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def update_cpu_set(self, additional_cpus):\n",
    "        self.cpu_set += f\",{additional_cpus}\" if self.cpu_set else additional_cpus\n",
    "\n",
    "    def runtime(self):\n",
    "        if self.start_time:\n",
    "            return time.time() - self.start_time\n",
    "        return 0\n",
    "    \n",
    "    def is_finished(self):\n",
    "        if not self.container:\n",
    "            return False        \n",
    "        try:\n",
    "            self.container.reload()\n",
    "            return self.container.status == 'exited'\n",
    "        except:\n",
    "            # Container might be removed already\n",
    "            return True\n",
    "\n",
    "start_queue = [Job(*job) for job in start_queue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c01d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started job radix on CPU 0\n",
      "Started job canneal on CPU 1\n",
      "Job radix completed after 35.22 seconds\n",
      "Released CPUs: 0. Available CPUs: ['0']\n",
      "Started job blackscholes on CPU 0\n",
      "Job blackscholes completed after 113.34 seconds\n",
      "Released CPUs: 0. Available CPUs: ['0']\n",
      "Started job dedup on CPU 0\n",
      "Job dedup completed after 26.76 seconds\n",
      "Released CPUs: 0. Available CPUs: ['0']\n",
      "Started job freqmine on CPU 0\n",
      "Job canneal completed after 188.13 seconds\n",
      "Released CPUs: 1. Available CPUs: ['1']\n",
      "Assigned CPU 1 to freqmine\n",
      "Job freqmine completed after 210.48 seconds\n",
      "Released CPUs: 0,1. Available CPUs: ['0', '1']\n",
      "Started job ferret on CPU 0\n",
      "Assigned CPU 1 to ferret\n",
      "Job ferret completed after 170.39 seconds\n",
      "Released CPUs: 0,1. Available CPUs: ['0', '1']\n",
      "Started job vips on CPU 0\n",
      "Job vips completed after 85.08 seconds\n",
      "Released CPUs: 0. Available CPUs: ['0']\n"
     ]
    }
   ],
   "source": [
    "curr_jobs: List[Job] = []\n",
    "avail_cpus = [\"0\", \"1\"]\n",
    "max_num_threads = 2\n",
    "\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "polling_interval = 0.1\n",
    "\n",
    "while len(start_queue) > 0 or len(curr_jobs) > 0:\n",
    "\n",
    "    for job in curr_jobs:\n",
    "        if job.is_finished():\n",
    "            print(f\"Job {job.name} completed after {job.runtime():.2f} seconds\")\n",
    "\n",
    "            # Free up the CPUs that were allocated to this job\n",
    "            for cpu in job.cpu_set.split(\",\"):\n",
    "                if cpu:  # Ensure it's not an empty string\n",
    "                    avail_cpus.append(cpu)\n",
    "\n",
    "            curr_jobs.remove(job)\n",
    "            print(f\"Released CPUs: {job.cpu_set}. Available CPUs: {avail_cpus}\")\n",
    "\n",
    "    if len(avail_cpus) == 0:\n",
    "        # print(\"No available CPUs, waiting...\")\n",
    "        sleep(polling_interval)\n",
    "        continue\n",
    "\n",
    "    avail_cpu = avail_cpus.pop(0)\n",
    "\n",
    "    # If we have a scaling job, we do not need to pop\n",
    "    scaling_jobs = [job for job in curr_jobs if job.is_scaling_job()]\n",
    "    if len(scaling_jobs) > 0:\n",
    "        scaling_job = scaling_jobs[0]\n",
    "\n",
    "        scaling_job.update_cpu_set(avail_cpu)\n",
    "\n",
    "        cpu_set = scaling_job.cpu_set\n",
    "        num_threads = len(cpu_set.split(\",\")) + 1\n",
    "\n",
    "        scaling_job.container.update(cpuset_cpus=cpu_set)\n",
    "        print(f\"Assigned CPU {avail_cpu} to {curr_jobs[0].name}\")\n",
    "        continue\n",
    "    \n",
    "    if len(start_queue) == 0:\n",
    "        # No more jobs to start\n",
    "        sleep(polling_interval)\n",
    "        continue\n",
    "\n",
    "    # Start a new job\n",
    "    job = start_queue.pop(0)\n",
    "\n",
    "    run_command = (\n",
    "        \"./run -a run -S splash2x -p radix -i native -n 1\"\n",
    "        if job.name == \"radix\"\n",
    "        else f\"./run -a run -S parsec -p {job.name} -i native -n {4 if job.is_scaling_job() else 1}\"\n",
    "    )\n",
    "    \n",
    "    container = client.containers.run(\n",
    "        image=job.image_name,\n",
    "        command=run_command,\n",
    "        detach=True,\n",
    "        remove=True,\n",
    "        name=\"parsec-\" + job.name,\n",
    "        cpuset_cpus=avail_cpu,\n",
    "    )\n",
    "\n",
    "    print(f\"Started job {job.name} on CPU {avail_cpu}\")\n",
    "    job.set_container(container)\n",
    "    job.update_cpu_set(avail_cpu)\n",
    "    curr_jobs.append(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d380b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# container = client.containers.run(\n",
    "#     image=image_dict[\"radix\"],\n",
    "#     command=f\"./run -a run -S parsec -p radix -i native -n {1}\",\n",
    "#     detach=True,\n",
    "#     remove=True,\n",
    "#     name='parsec-' + job.name,\n",
    "#     cpuset_cpus=avail_cpu\n",
    "# )\n",
    "\n",
    "# # print logs from the container\n",
    "# for line in container.logs(stream=True):\n",
    "#     print(line.strip())\n",
    "#     if b\"parsec\" in line:\n",
    "#         print(line.strip())\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399aeef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c3125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136b72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
