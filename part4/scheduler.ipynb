{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "from time import sleep\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "from os import getpid\n",
    "\n",
    "import psutil\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "formatted = now.isoformat()\n",
    "print(formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a034e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_client = docker.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48af272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {\n",
    "    \"blackscholes\": \"anakli/cca:parsec_blackscholes\",\n",
    "    \"canneal\": \"anakli/cca:parsec_canneal\",\n",
    "    \"dedup\": \"anakli/cca:parsec_dedup\",\n",
    "    \"ferret\": \"anakli/cca:parsec_ferret\",\n",
    "    \"freqmine\": \"anakli/cca:parsec_freqmine\",\n",
    "    \"radix\": \"anakli/cca:splash2x_radix\",\n",
    "    \"vips\": \"anakli/cca:parsec_vips\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29b454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = psutil.Process(getpid())\n",
    "p.cpu_affinity([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1361407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "poll_interval = 0.1  # seconds\n",
    "change_interval = 8 # seconds\n",
    "\n",
    "class DummyMemcachedStats:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.measurement = 0\n",
    "        self.measurement_time = time.time()\n",
    "\n",
    "    def read(self):\n",
    "        if time.time() - self.measurement_time > change_interval:\n",
    "            self.measurement = np.random.randint(0, 180000)\n",
    "            self.measurement_time = time.time()\n",
    "    \n",
    "    # queries received in the last count*10ms\n",
    "    def last_measurements(self, count=10):\n",
    "        self.read()\n",
    "        return self.measurement\n",
    "\n",
    "    def qps(self):\n",
    "        return self.last_measurements(int(1/poll_interval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d68506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = DummyMemcachedStats()\n",
    "# for i in range(20):\n",
    "#    print(tmp.last_measurements())\n",
    "#    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64942d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a67c9b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting queue:\n",
      "  radix: 1.95, 43 8\n",
      "  canneal: 1.7, 220 9\n",
      "  blackscholes: 1.7, 100 9\n",
      "  dedup: 1.7, 16 10\n",
      "  freqmine: 1.95, 394 11\n",
      "  ferret: 1.95, 288 11\n",
      "  vips: 1.95, 82 11\n"
     ]
    }
   ],
   "source": [
    "scaling = [1.70, 1.70, 1.70, 1.95, 1.95, 1.95, 1.95]\n",
    "duration = [100, 220, 16, 288, 394, 43, 82]\n",
    "interference = [9, 9, 10, 11, 11, 8, 11]\n",
    "\n",
    "jobs = list(zip(image_dict.keys(), scaling, duration, interference))\n",
    "\n",
    "start_queue = sorted(jobs, key=lambda x: (x[3], -x[2], x[1]), reverse=False)\n",
    "print(\"Starting queue:\")\n",
    "for job in start_queue:\n",
    "    print(f\"  {job[0]}: {job[1]}, {job[2]} {job[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5df035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97a4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    def __init__(self, name, scaling, duration, inteference):\n",
    "        self.name = name\n",
    "        self.scaling = scaling\n",
    "        self.duration = duration\n",
    "        self.interference = inteference\n",
    "        self.image_name = image_dict[name]\n",
    "        self.container = None\n",
    "        self.cpuset_cpus = \"\"\n",
    "        self.start_time = None  # Initialize start_time to None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Job({self.name}, {self.scaling}, {self.duration}, {self.interference})\"\n",
    "    \n",
    "    def is_scaling_job(self):\n",
    "        return self.scaling > 1.9 and self.interference > 10\n",
    "    \n",
    "    def set_container(self, container):\n",
    "        self.container = container\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def update_cpusets_cpu(self, additional_cpus):\n",
    "        self.cpuset_cpus += f\",{additional_cpus}\" if self.cpuset_cpus else additional_cpus\n",
    "\n",
    "        self.container.reload()\n",
    "        if self.container.status == 'running':\n",
    "            self.container.update(cpuset_cpus=self.cpuset_cpus)\n",
    "\n",
    "    def remove_cpu(self, cpu):\n",
    "        # Fix the remove_cpu method\n",
    "        cpu_list = self.cpuset_cpus.split(\",\")\n",
    "        if cpu in cpu_list:\n",
    "            cpu_list.remove(cpu)\n",
    "            self.cpuset_cpus = \",\".join(cpu_list)\n",
    "            self.container.update(cpuset_cpus=self.cpuset_cpus)\n",
    "\n",
    "    def runtime(self):\n",
    "        if self.start_time:\n",
    "            return time.time() - self.start_time\n",
    "        return 0\n",
    "    \n",
    "    def is_finished(self):\n",
    "        if not self.container:\n",
    "            return False        \n",
    "        try:\n",
    "            self.container.reload()\n",
    "            return self.container.status == 'exited'\n",
    "        except:\n",
    "            # Container might be removed already\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c01d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CPU affinity of Memcached to 0 with QPS 0\n",
      "Available CPUs: ['1', '2', '3']\n",
      "Started job radix on CPU 1\n",
      "Available CPUs: ['2', '3']\n",
      "Started job canneal on CPU 2\n",
      "Available CPUs: ['3']\n",
      "Started job blackscholes on CPU 3\n",
      "New QPS: 154750\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 154750\n",
      "Pausing job radix on CPU 1 due to high QPS\n",
      "New QPS: 50247\n",
      "Setting CPU affinity of Memcached to 0 with QPS 50247\n",
      "Available CPUs: ['1']\n",
      "Job radix unpaused and assigned to CPU 1\n",
      "New QPS: 122496\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 122496\n",
      "Pausing job radix on CPU 1 due to high QPS\n",
      "New QPS: 112255\n",
      "New QPS: 138978\n",
      "New QPS: 54779\n",
      "Setting CPU affinity of Memcached to 0 with QPS 54779\n",
      "Available CPUs: ['1']\n",
      "Job radix unpaused and assigned to CPU 1\n",
      "New QPS: 141026\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 141026\n",
      "Pausing job radix on CPU 1 due to high QPS\n",
      "New QPS: 174348\n",
      "New QPS: 108063\n",
      "New QPS: 30501\n",
      "Setting CPU affinity of Memcached to 0 with QPS 30501\n",
      "Available CPUs: ['1']\n",
      "Job radix unpaused and assigned to CPU 1\n",
      "New QPS: 131696\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 131696\n",
      "Pausing job radix on CPU 1 due to high QPS\n",
      "New QPS: 102767\n",
      "Job blackscholes completed after 107.97 seconds\n",
      "Released CPUs: 3. Available CPUs: ['3']\n",
      "Available CPUs: ['3']\n",
      "Job radix unpaused and assigned to CPU 3\n",
      "Setting CPU affinity of Memcached to 0 with QPS 95404\n",
      "Available CPUs: ['1']\n",
      "Started job dedup on CPU 1\n",
      "Job radix completed after 116.05 seconds\n",
      "Released CPUs: 3. Available CPUs: ['3']\n",
      "Available CPUs: ['3']\n",
      "Started job freqmine on CPU 3\n",
      "New QPS: 69409\n",
      "New QPS: 58021\n",
      "New QPS: 40119\n",
      "Job dedup completed after 26.40 seconds\n",
      "Released CPUs: 1. Available CPUs: ['1']\n",
      "Available CPUs: ['1']\n",
      "Added CPU 1 to freqmine\n",
      "New QPS: 71615\n",
      "New QPS: 137535\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 137535\n",
      "New QPS: 102985\n",
      "New QPS: 174580\n",
      "Job canneal completed after 170.17 seconds\n",
      "Released CPUs: 2. Available CPUs: ['2']\n",
      "Available CPUs: ['2']\n",
      "Added CPU 2 to freqmine\n",
      "New QPS: 159834\n",
      "New QPS: 31050\n",
      "Setting CPU affinity of Memcached to 0 with QPS 31050\n",
      "Available CPUs: ['1']\n",
      "Added CPU 1 to freqmine\n",
      "New QPS: 110493\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 110493\n",
      "New QPS: 165940\n",
      "New QPS: 10869\n",
      "Setting CPU affinity of Memcached to 0 with QPS 10869\n",
      "Available CPUs: ['1']\n",
      "Added CPU 1 to freqmine\n",
      "New QPS: 76136\n",
      "New QPS: 37528\n",
      "New QPS: 71827\n",
      "New QPS: 37386\n",
      "New QPS: 14082\n",
      "New QPS: 120865\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 120865\n",
      "Job freqmine completed after 160.11 seconds\n",
      "Released CPUs: 3,1,2,1,1. Available CPUs: ['3', '1', '2']\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 120865\n",
      "Available CPUs: ['3', '2']\n",
      "Started job ferret on CPU 3\n",
      "Available CPUs: ['2']\n",
      "Added CPU 2 to ferret\n",
      "New QPS: 26103\n",
      "Setting CPU affinity of Memcached to 0 with QPS 26103\n",
      "Available CPUs: ['1']\n",
      "Added CPU 1 to ferret\n",
      "New QPS: 121029\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 121029\n",
      "New QPS: 145164\n",
      "New QPS: 118897\n",
      "New QPS: 91046\n",
      "Setting CPU affinity of Memcached to 0 with QPS 91046\n",
      "Available CPUs: ['1']\n",
      "Added CPU 1 to ferret\n",
      "New QPS: 45544\n",
      "New QPS: 20340\n",
      "New QPS: 150049\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 150049\n",
      "New QPS: 100156\n",
      "New QPS: 43169\n",
      "Setting CPU affinity of Memcached to 0 with QPS 43169\n",
      "Available CPUs: ['1']\n",
      "Added CPU 1 to ferret\n",
      "New QPS: 9811\n",
      "New QPS: 123319\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 123319\n",
      "New QPS: 2101\n",
      "Setting CPU affinity of Memcached to 0 with QPS 2101\n",
      "Available CPUs: ['1']\n",
      "Added CPU 1 to ferret\n",
      "Job ferret completed after 115.01 seconds\n",
      "Released CPUs: 3,2,1,1,1,1. Available CPUs: ['3', '2', '1']\n",
      "Available CPUs: ['3', '2', '1']\n",
      "Started job vips on CPU 3\n",
      "Available CPUs: ['2', '1']\n",
      "Added CPU 2 to vips\n",
      "Available CPUs: ['1']\n",
      "Added CPU 1 to vips\n",
      "New QPS: 56323\n",
      "New QPS: 2760\n",
      "New QPS: 105897\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 105897\n",
      "Job vips completed after 32.45 seconds\n",
      "Released CPUs: 3,2,1. Available CPUs: ['3', '2', '1']\n",
      "Setting CPU affinity of Memcached to 0, 1 with QPS 115304\n"
     ]
    }
   ],
   "source": [
    "start_queue = [Job(*job) for job in start_queue]\n",
    "curr_jobs: List[Job] = []\n",
    "\n",
    "avail_cpus = [\"2\", \"3\"]\n",
    "\n",
    "\n",
    "cpu_1_used = False\n",
    "cpu_1_job = None\n",
    "\n",
    "mem_cached_measurments = DummyMemcachedStats()\n",
    "\n",
    "memcached_id = 0#[p.pid for p in psutil.process_iter(['name']) if p.info['name'] == 'memcached'][0]\n",
    "#memcached = psutil.Process(memcached_id)\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "polling_interval = 0.1\n",
    "prev_qps = 0\n",
    "\n",
    "while len(start_queue) > 0 or len(curr_jobs) > 0:\n",
    "\n",
    "    # Check if any job has finished\n",
    "    for job in curr_jobs:\n",
    "        if job.is_finished():\n",
    "            print(f\"Job {job.name} completed after {job.runtime():.2f} seconds\")\n",
    "\n",
    "            # Free up the CPUs that were allocated to this job\n",
    "            for cpu in job.cpuset_cpus.split(\",\"):\n",
    "                if cpu and cpu not in avail_cpus:\n",
    "                    avail_cpus.append(cpu)\n",
    "            \n",
    "            curr_jobs.remove(job)\n",
    "            if job == cpu_1_job:\n",
    "                cpu_1_job = None\n",
    "\n",
    "            print(f\"Released CPUs: {job.cpuset_cpus}. Available CPUs: {avail_cpus}\")\n",
    "\n",
    "    # Get the current CPU and QPS\n",
    "    cpu_cores_usage = psutil.cpu_percent(interval=None, percpu=True)\n",
    "    qps = mem_cached_measurments.last_measurements()\n",
    "\n",
    "    if abs(prev_qps - qps) > 10000:\n",
    "        print(f\"New QPS: {qps}\")\n",
    "        prev_qps = qps\n",
    "\n",
    "    if qps < 100000 and not cpu_1_used and not (\"1\" in avail_cpus):\n",
    "        # print(\"Low QPS, assigning more CPUS...\")\n",
    "        cpu_1_used = True\n",
    "        \n",
    "        avail_cpus.insert(0, \"1\")\n",
    "        # memcached.cpu_affinity([0])\n",
    "        print(f\"Setting CPU affinity of Memcached to 0 with QPS {qps}\")\n",
    "    elif (\"1\" in avail_cpus or cpu_1_used) and not (qps < 100000):\n",
    "        # print(\"High QPS, releasing CPU 1...\")\n",
    "        \n",
    "        cpu_1_used = False\n",
    "\n",
    "        if \"1\" in avail_cpus:\n",
    "            avail_cpus.remove(\"1\")\n",
    "        # memcached.cpu_affinity([0, 1])\n",
    "        print(f\"Setting CPU affinity of Memcached to 0, 1 with QPS {qps}\")\n",
    "\n",
    "        if cpu_1_job is None:\n",
    "            continue\n",
    "    \n",
    "        if len(cpu_1_job.cpuset_cpus.split(\",\")) == 1:\n",
    "            print(f\"Pausing job {cpu_1_job.name} on CPU 1 due to high QPS\")\n",
    "            cpu_1_job.container.pause()\n",
    "            curr_jobs.remove(cpu_1_job)\n",
    "            start_queue.insert(0, cpu_1_job)\n",
    "            cpu_1_job.cpuset_cpus = \"\"\n",
    "            cpu_1_job = None\n",
    "        else:\n",
    "            cpu_1_job.remove_cpu(\"1\")\n",
    "            print(f\"Removing CPU 1 from job {cpu_1_job.name} due to high QPS\")\n",
    "\n",
    "    if len(avail_cpus) == 0:\n",
    "        # print(\"No available CPUs, waiting...\")\n",
    "\n",
    "        sleep(polling_interval)\n",
    "        continue\n",
    "\n",
    "    print(f\"Available CPUs: {avail_cpus}\")\n",
    "            \n",
    "    avail_cpu = avail_cpus.pop(0)\n",
    "\n",
    "    # If we have a scaling job, we do not need to pop\n",
    "    if len(start_queue) == 0:\n",
    "        scaling_jobs = [job for job in curr_jobs if job.is_scaling_job()] or curr_jobs\n",
    "    else:\n",
    "        scaling_jobs = [job for job in curr_jobs if job.is_scaling_job()]\n",
    "\n",
    "    if len(scaling_jobs) > 0:\n",
    "        scaling_job = scaling_jobs[0]\n",
    "\n",
    "        scaling_job.update_cpusets_cpu(avail_cpu)\n",
    "\n",
    "        cpuset_cpus = scaling_job.cpuset_cpus\n",
    "\n",
    "        print(f\"Added CPU {avail_cpu} to {scaling_job.name}\")\n",
    "        continue\n",
    "    \n",
    "    if len(start_queue) == 0:\n",
    "        # No more jobs to start\n",
    "        sleep(polling_interval)\n",
    "        continue\n",
    "\n",
    "    #\n",
    "    job = start_queue.pop(0)\n",
    "\n",
    "    # Job already started but was paused\n",
    "    if job.container is not None:\n",
    "        print(f\"Job {job.name} unpaused and assigned to CPU {avail_cpu}\")\n",
    "        curr_jobs.append(job)\n",
    "        job.container.update(cpuset_cpus=avail_cpu)\n",
    "        job.cpuset_cpus = avail_cpu\n",
    "        job.container.unpause()\n",
    "        \n",
    "        if avail_cpu == \"1\":\n",
    "            cpu_1_job = job\n",
    "\n",
    "        continue\n",
    "\n",
    "    run_command = (\n",
    "        \"./run -a run -S splash2x -p radix -i native -n 1\"\n",
    "        if job.name == \"radix\"\n",
    "        else f\"./run -a run -S parsec -p {job.name} -i native -n {3 if job.is_scaling_job() else 1}\"\n",
    "    )\n",
    "    \n",
    "    container = client.containers.run(\n",
    "        image=job.image_name,\n",
    "        command=run_command,\n",
    "        detach=True,\n",
    "        remove=True,\n",
    "        name=\"parsec-\" + job.name,\n",
    "        cpuset_cpus=avail_cpu,\n",
    "    )\n",
    "\n",
    "    print(f\"Started job {job.name} on CPU {avail_cpu}\")\n",
    "    job.set_container(container)\n",
    "    job.cpuset_cpus = avail_cpu\n",
    "    curr_jobs.append(job)\n",
    "\n",
    "    if avail_cpu == \"1\":\n",
    "        cpu_1_job = job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380b098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399aeef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c3125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136b72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
